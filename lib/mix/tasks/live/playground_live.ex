# defmodule JidoAI.PlaygroundLive do
#   use Phoenix.LiveView

#   alias Jido.AI.{CostCalculator, Keyring, Message, TokenCounter}

#   @default_model "openrouter:openai/gpt-oss-20b:free"

#   def mount(_params, _session, socket) do
#     IO.puts("ğŸ”§ PlaygroundLive mounting...")

#     providers = Jido.AI.Provider.Registry.list_providers() |> sort_alphabetically()
#     IO.puts("ğŸ”§ Found #{length(providers)} providers: #{inspect(providers)}")

#     default_provider = :openrouter
#     available_models = get_models_for_provider(default_provider) |> sort_models_alphabetically()
#     IO.puts("ğŸ”§ Found #{length(available_models)} models for #{default_provider}")

#     # Set a test API key for openrouter if none exists
#     if Jido.AI.config([default_provider, :api_key]) == nil do
#       IO.puts("ğŸ”§ Setting test API key for openrouter")
#       Keyring.set_session_value(:openrouter_api_key, "sk-or-v1-test123456789")
#     end

#     # Check API key availability
#     api_key_status = check_api_keys(providers)
#     IO.puts("ğŸ”§ API Key Status: #{inspect(api_key_status)}")

#     # Find the default model in the available models
#     default_model = "openai/gpt-oss-20b"

#     auto_selected_model =
#       if Enum.any?(available_models, fn {model_id, _model} -> model_id == default_model end) do
#         IO.puts("ğŸ”§ Auto-selecting default model: #{default_model}")
#         default_model
#       else
#         first_model_tuple = List.first(available_models)

#         first_model_id =
#           case first_model_tuple do
#             {model_id, _} -> model_id
#             _ -> default_model
#           end

#         IO.puts("ğŸ”§ Default model not found, using first available: #{first_model_id}")
#         first_model_id
#       end

#     {:ok,
#      assign(socket,
#        # Tabs and UI
#        active_tab: :text_generation,

#        # Provider & Model
#        providers: providers,
#        selected_provider: default_provider,
#        available_models: available_models,
#        selected_model: auto_selected_model,
#        model_spec: @default_model,
#        api_key_status: api_key_status,

#        # Text Generation
#        messages: [],
#        input: "",
#        loading: false,
#        current_assistant_id: nil,

#        # Generation Options
#        temperature: 0.7,
#        max_tokens: 1000,
#        system_prompt: "You are a helpful assistant.",

#        # Structured Data
#        schema_input:
#          "name: [type: :string, required: true],\nage: [type: :integer, default: 25],\nemail: [type: :string, required: true]",
#        output_type: :object,
#        structured_result: nil,

#        # Message Builder
#        message_mode: :simple,
#        current_messages: [],

#        # Metrics
#        total_input_tokens: 0,
#        total_output_tokens: 0,
#        total_cost: 0.0,
#        api_calls: 0,
#        session_start: System.system_time(:millisecond),
#        current_request_cost: nil
#      )}
#   end

#   def render(assigns) do
#     ~H"""
#     <!DOCTYPE html>
#     <html lang="en" class="dark">
#     <head>
#       <meta charset="UTF-8">
#       <meta name="viewport" content="width=device-width, initial-scale=1.0">
#       <title>Jido AI Playground</title>
#       <script src="https://cdn.tailwindcss.com"></script>
#       <script>
#         tailwind.config = {
#           darkMode: 'class',
#           theme: {
#             extend: {
#               colors: {
#                 github: {
#                   canvas: '#0d1117',
#                   secondary: '#161b22',
#                   tertiary: '#21262d',
#                   border: '#30363d',
#                   text: '#f0f6fc',
#                   muted: '#8b949e',
#                   accent: '#58a6ff',
#                   success: '#238636',
#                   danger: '#da3633'
#                 }
#               }
#             }
#           }
#         }
#       </script>
#     </head>
#     <body class="bg-github-canvas text-github-text h-screen overflow-hidden">
#       <div class="h-screen flex flex-col">
#         <!-- Header -->
#         <header class="bg-github-secondary border-b border-github-border px-5 py-3 flex justify-between items-center flex-shrink-0">
#           <div class="flex items-center gap-3">
#             <div class="flex items-center gap-2">
#               <span class="text-github-accent font-mono text-lg font-bold">></span>
#               <span class="text-base font-semibold">Jido AI Playground</span>
#             </div>
#             <div class="bg-blue-600 text-white px-2 py-1 rounded-xl text-xs font-medium">
#               Developer Testing Interface
#             </div>
#           </div>
#           <div class="flex items-center gap-3">
#             <span class="text-github-muted text-sm"><%= @api_calls %> messages</span>
#             <button class="bg-github-danger text-white px-3 py-1.5 rounded-md text-xs hover:bg-red-700 transition-colors" phx-click="reset_session">
#               Reset All
#             </button>
#           </div>
#         </header>

#         <!-- Tab Navigation -->
#         <nav class="bg-github-secondary border-b border-github-border px-5 flex gap-0 flex-shrink-0">
#           <button
#             class={"text-github-muted px-4 py-3 text-sm flex items-center gap-1.5 border-b-2 border-transparent transition-all hover:text-github-text " <> if(@active_tab == :text_generation, do: "text-github-accent border-github-accent", else: "")}
#             phx-click="switch_tab"
#             phx-value-tab="text_generation"
#           >
#             <span class="text-base">ğŸ’¬</span>
#             Text Generation
#           </button>
#           <button
#             class={"text-github-muted px-4 py-3 text-sm flex items-center gap-1.5 border-b-2 border-transparent transition-all hover:text-github-text " <> if(@active_tab == :structured_data, do: "text-github-accent border-github-accent", else: "")}
#             phx-click="switch_tab"
#             phx-value-tab="structured_data"
#           >
#             <span class="text-base">ğŸ“Š</span>
#             Structured Data
#           </button>
#           <button
#             class={"text-github-muted px-4 py-3 text-sm flex items-center gap-1.5 border-b-2 border-transparent transition-all hover:text-github-text " <> if(@active_tab == :message_builder, do: "text-github-accent border-github-accent", else: "")}
#             phx-click="switch_tab"
#             phx-value-tab="message_builder"
#           >
#             <span class="text-base">ğŸ”§</span>
#             Message Builder
#           </button>
#           <button
#             class={"text-github-muted px-4 py-3 text-sm flex items-center gap-1.5 border-b-2 border-transparent transition-all hover:text-github-text " <> if(@active_tab == :analytics, do: "text-github-accent border-github-accent", else: "")}
#             phx-click="switch_tab"
#             phx-value-tab="analytics"
#           >
#             <span class="text-base">ğŸ“ˆ</span>
#             Analytics
#           </button>
#         </nav>

#         <div class="flex flex-1 overflow-hidden">
#           <!-- Main Content -->
#           <div class="flex-1 p-5 overflow-y-auto bg-github-canvas border-r border-github-border">
#             <%= case @active_tab do %>
#               <% :text_generation -> %>
#                 <%= render_text_generation(assigns) %>
#               <% :structured_data -> %>
#                 <%= render_structured_data(assigns) %>
#               <% :message_builder -> %>
#                 <%= render_message_builder(assigns) %>
#               <% :analytics -> %>
#                 <%= render_analytics(assigns) %>
#             <% end %>
#           </div>

#           <!-- Sidebar -->
#           <div class="w-80 bg-github-secondary p-5 overflow-y-auto border-l border-github-border">
#             <%= render_sidebar(assigns) %>
#           </div>
#         </div>
#       </div>
#     </body>
#     </html>

#     <style>
#       .valid { border-color: #238636 !important; }
#       .invalid { border-color: #da3633 !important; }

#       /* Custom scrollbar for webkit browsers */
#       ::-webkit-scrollbar { width: 8px; }
#       ::-webkit-scrollbar-track { background: #21262d; }
#       ::-webkit-scrollbar-thumb { background: #30363d; border-radius: 4px; }
#       ::-webkit-scrollbar-thumb:hover { background: #484f58; }

#       /* Spinner animation */
#       @keyframes spin { to { transform: rotate(360deg); } }
#       .spinner {
#         display: inline-block; width: 12px; height: 12px;
#         border: 2px solid #30363d; border-radius: 50%;
#         border-top-color: #58a6ff; animation: spin 1s ease-in-out infinite;
#       }
#     </style>

#     <script>
#       // Auto-scroll chat to bottom on new messages
#       window.addEventListener("phx:stream_chunk", () => {
#         const chatContainer = document.getElementById("chat");
#         if (chatContainer) {
#           chatContainer.scrollTop = chatContainer.scrollHeight;
#         }
#       });

#       // Auto-scroll on page updates (for message additions)
#       document.addEventListener("DOMContentLoaded", () => {
#         const observer = new MutationObserver(() => {
#           const chatContainer = document.getElementById("chat");
#           if (chatContainer) {
#             chatContainer.scrollTop = chatContainer.scrollHeight;
#           }
#         });

#         const chatContainer = document.getElementById("chat");
#         if (chatContainer) {
#           observer.observe(chatContainer, { childList: true, subtree: true });
#         }
#       });
#     </script>
#     """
#   end

#   # Tab Content Renderers
#   defp render_text_generation(assigns) do
#     ~H"""
#     <div class="h-full flex flex-col">
#       <div class="mb-5 pb-3 border-b border-github-border">
#         <h2 class="text-lg font-semibold text-github-text mb-1">Text Generation Hub</h2>
#         <p class="text-sm text-github-muted">Test your model configurations and prompts</p>
#       </div>

#       <div class="border border-github-border rounded-lg flex-1 overflow-y-auto p-4 mb-5 bg-github-canvas min-h-96 space-y-4" id="chat">
#         <%= if Enum.empty?(@messages) do %>
#           <div class="text-github-muted p-10 text-center">
#             <p class="mb-2">ğŸ‘‹ Start a conversation with your AI model</p>
#             <p>Type a message below to begin testing</p>
#           </div>
#         <% else %>
#           <%= for message <- @messages do %>
#             <div class={"flex " <> if(message.role == "user", do: "justify-end", else: "justify-start")} id={"msg-" <> message.id}>
#               <div class={if message.role == "user" do
#                 "bg-blue-600 text-white px-4 py-3 rounded-lg rounded-br-md max-w-lg break-words"
#               else
#                 "bg-github-tertiary text-github-text px-4 py-3 rounded-lg rounded-bl-md max-w-lg break-words border border-github-border"
#               end}>
#                 <%= if message.role == "assistant" do %>
#                   <div class="prose prose-invert prose-sm max-w-none">
#                     <%= Phoenix.HTML.raw(format_markdown(message.content)) %>
#                   </div>
#                 <% else %>
#                   <%= message.content %>
#                 <% end %>
#               </div>
#             </div>
#           <% end %>
#         <% end %>
#       </div>

#       <form phx-submit="send_message" class="mt-auto">
#         <div class="flex gap-2.5">
#           <input
#             type="text"
#             name="message"
#             value={@input}
#             phx-change="input_change"
#             placeholder="Enter your prompt..."
#             disabled={@loading}
#             autofocus
#             class="flex-1 px-3 py-3 bg-github-tertiary border border-github-border rounded-md text-base text-github-text placeholder-github-muted focus:outline-none focus:border-github-accent focus:ring-2 focus:ring-github-accent/30"
#           />
#           <button type="submit" class="px-6 py-3 bg-github-success text-white rounded-md font-medium text-base transition-colors hover:bg-green-700 disabled:bg-gray-600 disabled:cursor-not-allowed flex items-center gap-2" disabled={@loading or @input == ""}>
#             <%= if @loading do %>
#               <span class="spinner"></span> Generating...
#             <% else %>
#               âœ¨ Generate
#             <% end %>
#           </button>
#         </div>
#       </form>
#     </div>
#     """
#   end

#   defp render_structured_data(assigns) do
#     ~H"""
#     <div class="h-full flex flex-col">
#       <div class="mb-5 pb-3 border-b border-github-border">
#         <h2 class="text-lg font-semibold text-github-text mb-1">Structured Data Sandbox</h2>
#         <p class="text-sm text-github-muted">Test schema validation and object generation</p>
#       </div>

#       <div class="grid grid-cols-1 lg:grid-cols-2 gap-5 flex-1">
#         <div class="flex flex-col">
#           <label class="text-github-muted text-sm font-medium mb-1.5">Schema Definition (NimbleOptions format)</label>
#           <textarea
#             class="bg-github-tertiary border border-github-border rounded-md p-3 font-mono text-sm text-github-text min-h-32 resize-y flex-1 focus:outline-none focus:border-github-accent focus:ring-2 focus:ring-github-accent/30"
#             name="value"
#             phx-change="update_schema"
#             phx-debounce="500"
#             placeholder="name: [type: :string, required: true],&#10;age: [type: :integer, default: 0]"
#           ><%= @schema_input %></textarea>

#           <div class="flex gap-3 my-4">
#             <button
#               class={"px-4 py-2 rounded-md text-sm transition-all " <> if(@output_type == :object, do: "bg-blue-600 text-white border-blue-600", else: "bg-github-tertiary text-github-muted border border-github-border hover:bg-github-border hover:text-github-text")}
#               phx-click="set_output_type"
#               phx-value-type="object"
#             >Object</button>
#             <button
#               class={"px-4 py-2 rounded-md text-sm transition-all " <> if(@output_type == :array, do: "bg-blue-600 text-white border-blue-600", else: "bg-github-tertiary text-github-muted border border-github-border hover:bg-github-border hover:text-github-text")}
#               phx-click="set_output_type"
#               phx-value-type="array"
#             >Array</button>
#             <button
#               class={"px-4 py-2 rounded-md text-sm transition-all " <> if(@output_type == :enum, do: "bg-blue-600 text-white border-blue-600", else: "bg-github-tertiary text-github-muted border border-github-border hover:bg-github-border hover:text-github-text")}
#               phx-click="set_output_type"
#               phx-value-type="enum"
#             >Enum</button>
#           </div>

#           <button class="px-6 py-3 bg-github-success text-white rounded-md font-medium transition-colors hover:bg-green-700 disabled:bg-gray-600 disabled:cursor-not-allowed" phx-click="generate_structured" disabled={@loading}>
#             <%= if @loading, do: "Generating...", else: "Generate Object" %>
#           </button>
#         </div>

#         <div class="flex flex-col">
#           <label class="text-github-muted text-sm font-medium mb-1.5">Generated Result</label>
#           <div class="bg-github-canvas border border-github-border rounded-md p-4 font-mono text-sm text-github-text min-h-48 whitespace-pre-wrap overflow-x-auto flex-1">
#             <%= if @structured_result do %>
#               <%= Jason.encode!(@structured_result, pretty: true) %>
#             <% else %>
#               <div class="text-github-muted p-5 text-center">
#                 <p class="mb-2">ğŸ“Š Generated objects will appear here</p>
#                 <p>Configure your schema and click "Generate Object"</p>
#               </div>
#             <% end %>
#           </div>
#         </div>
#       </div>
#     </div>
#     """
#   end

#   defp render_message_builder(assigns) do
#     ~H"""
#     <div class="h-full flex flex-col">
#       <div class="mb-5 pb-3 border-b border-github-border">
#         <h2 class="text-lg font-semibold text-github-text mb-1">Message Builder</h2>
#         <p class="text-sm text-github-muted">Compose rich conversations with multi-modal content</p>
#       </div>

#       <div class="text-github-muted p-10 text-center">
#         <p>Coming soon - Rich message composition with image/file support</p>
#       </div>
#     </div>
#     """
#   end

#   defp render_analytics(assigns) do
#     ~H"""
#     <div class="h-full flex flex-col">
#       <div class="mb-5 pb-3 border-b border-github-border">
#         <h2 class="text-lg font-semibold text-github-text mb-1">Performance Analytics</h2>
#         <p class="text-sm text-github-muted">Monitor usage, costs, and performance metrics</p>
#       </div>

#       <div class="text-github-muted p-10 text-center">
#         <p>Coming soon - Real-time metrics and cost tracking</p>
#       </div>
#     </div>
#     """
#   end

#   defp render_sidebar(assigns) do
#     ~H"""
#     <div class="mb-6">
#       <h3 class="text-sm font-semibold text-github-text mb-3 flex items-center gap-1.5">
#         ğŸ¤– Provider & Model
#       </h3>

#       <div class="mb-4">
#         <div class="flex items-center justify-between mb-1.5">
#           <label class="text-github-muted text-xs font-medium">Provider</label>
#           <%= case Enum.find(@api_key_status, fn {p, _} -> p == @selected_provider end) do %>
#             <% {_, :available} -> %>
#               <span class="text-github-success text-xs">ğŸ”‘ API Key OK</span>
#             <% {_, :missing} -> %>
#               <span class="text-github-danger text-xs">ğŸ”‘ No API Key</span>
#             <% _ -> %>
#               <span class="text-github-muted text-xs">ğŸ”‘ Unknown</span>
#           <% end %>
#         </div>
#         <form phx-change="change_provider">
#           <select name="value" class="w-full bg-github-tertiary border border-github-border text-github-text px-2.5 py-2 rounded-md text-xs cursor-pointer focus:outline-none focus:border-github-accent focus:ring-2 focus:ring-github-accent/30">
#             <%= for provider <- @providers do %>
#               <option value={provider} selected={provider == @selected_provider}>
#                 <%= provider |> to_string() |> String.capitalize() %>
#               </option>
#             <% end %>
#           </select>
#         </form>
#       </div>

#       <div class="mb-4">
#         <label class="text-github-muted text-xs font-medium mb-1.5 block">Model</label>
#         <form phx-change="change_model">
#           <select name="value" class="w-full bg-github-tertiary border border-github-border text-github-text px-2.5 py-2 rounded-md text-xs cursor-pointer focus:outline-none focus:border-github-accent focus:ring-2 focus:ring-github-accent/30">
#             <%= for {model_id, _model} <- @available_models do %>
#               <option value={model_id} selected={model_id == @selected_model}>
#                 <%= model_id %>
#               </option>
#             <% end %>
#           </select>
#         </form>
#       </div>
#     </div>

#     <div class="mb-6">
#       <h3 class="text-sm font-semibold text-github-text mb-3 flex items-center gap-1.5">
#         âš™ï¸ Generation Options
#       </h3>

#       <div class="mb-4">
#         <label class="text-github-muted text-xs font-medium mb-1.5 block">Temperature: <%= @temperature %></label>
#         <input
#           type="range"
#           class="w-full h-1.5 bg-github-border rounded-md appearance-none cursor-pointer slider"
#           name="value"
#           min="0"
#           max="2"
#           step="0.1"
#           value={@temperature}
#           phx-change="update_temperature"
#         />
#       </div>

#       <div class="mb-4">
#         <label class="text-github-muted text-xs font-medium mb-1.5 block">Max Tokens</label>
#         <input
#           type="number"
#           class="w-full bg-github-tertiary border border-github-border text-github-text px-2.5 py-2 rounded-md text-xs focus:outline-none focus:border-github-accent focus:ring-2 focus:ring-github-accent/30"
#           name="value"
#           value={@max_tokens}
#           phx-change="update_max_tokens"
#           min="1"
#           max="32000"
#         />
#       </div>

#       <div class="mb-4">
#         <label class="text-github-muted text-xs font-medium mb-1.5 block">System Prompt</label>
#         <textarea
#           class="w-full bg-github-tertiary border border-github-border text-github-text px-2.5 py-2 rounded-md text-xs resize-y min-h-15 focus:outline-none focus:border-github-accent focus:ring-2 focus:ring-github-accent/30"
#           name="value"
#           phx-change="update_system_prompt"
#           phx-debounce="300"
#           placeholder="You are a helpful assistant..."
#         ><%= @system_prompt %></textarea>
#       </div>
#     </div>

#     <div class="mb-6">
#       <h3 class="text-sm font-semibold text-github-text mb-3 flex items-center gap-1.5">
#         ğŸ“Š Quick Metrics
#       </h3>
#       <div class="grid grid-cols-2 gap-3">
#         <div class="bg-github-tertiary p-3 rounded-md border border-github-border">
#           <div class="text-github-muted text-xs mb-1">Input Tokens</div>
#           <div class="text-github-text text-base font-semibold text-github-success"><%= @total_input_tokens %></div>
#         </div>
#         <div class="bg-github-tertiary p-3 rounded-md border border-github-border">
#           <div class="text-github-muted text-xs mb-1">Output Tokens</div>
#           <div class="text-github-text text-base font-semibold text-blue-400"><%= @total_output_tokens %></div>
#         </div>
#         <div class="bg-github-tertiary p-3 rounded-md border border-github-border">
#           <div class="text-github-muted text-xs mb-1">Total Cost</div>
#           <div class="text-github-text text-base font-semibold text-github-accent">$<%= :io_lib.format("~.6f", [@total_cost]) %></div>
#         </div>
#         <div class="bg-github-tertiary p-3 rounded-md border border-github-border">
#           <div class="text-github-muted text-xs mb-1">API Calls</div>
#           <div class="text-github-text text-base font-semibold text-orange-400"><%= @api_calls %></div>
#         </div>
#       </div>

#       <%= if @current_request_cost do %>
#         <div class="mt-3 bg-github-tertiary p-3 rounded-md border border-github-border">
#           <div class="text-github-muted text-xs mb-1">Last Request</div>
#           <div class="text-github-text text-sm">
#             <%= CostCalculator.format_cost(@current_request_cost) %>
#           </div>
#         </div>
#       <% end %>
#     </div>

#     <div class="mt-auto">
#       <h3 class="text-sm font-semibold text-github-text mb-3 flex items-center gap-1.5">
#         ğŸ› ï¸ Developer Tools
#       </h3>
#       <button class="w-full bg-github-tertiary border border-github-border text-github-text px-2.5 py-2.5 rounded-md cursor-pointer mb-2 text-xs text-left transition-colors hover:bg-github-border" phx-click="export_session">Export Session</button>
#       <button class="w-full bg-github-tertiary border border-github-border text-github-text px-2.5 py-2.5 rounded-md cursor-pointer mb-2 text-xs text-left transition-colors hover:bg-github-border" phx-click="generate_code">Generate Code</button>
#       <button class="w-full bg-red-600 border border-red-500 text-white px-2.5 py-2.5 rounded-md cursor-pointer mb-2 text-xs text-left transition-colors hover:bg-red-700" phx-click="reset_metrics">Reset Metrics</button>
#       <button class="w-full bg-github-tertiary border border-github-border text-github-text px-2.5 py-2.5 rounded-md cursor-pointer mb-2 text-xs text-left transition-colors hover:bg-github-border" phx-click="view_raw_response">View Raw Response</button>
#     </div>
#     """
#   end

#   # Event Handlers
#   def handle_event("switch_tab", %{"tab" => tab}, socket) do
#     {:noreply, assign(socket, active_tab: String.to_atom(tab))}
#   end

#   def handle_event("reset_session", _params, socket) do
#     {:noreply,
#      assign(socket,
#        messages: [],
#        input: "",
#        loading: false,
#        current_assistant_id: nil,
#        total_input_tokens: 0,
#        total_output_tokens: 0,
#        total_cost: 0.0,
#        api_calls: 0,
#        current_request_cost: nil,
#        structured_result: nil
#      )}
#   end

#   def handle_event("reset_metrics", _params, socket) do
#     IO.puts("ğŸ”§ Resetting metrics...")

#     {:noreply,
#      assign(socket,
#        total_input_tokens: 0,
#        total_output_tokens: 0,
#        total_cost: 0.0,
#        api_calls: 0,
#        current_request_cost: nil
#      )}
#   end

#   def handle_event("update_temperature", params, socket) do
#     temp = params["value"] || params["temperature"]
#     {temp_float, _} = Float.parse(temp)
#     {:noreply, assign(socket, temperature: temp_float)}
#   end

#   def handle_event("update_max_tokens", params, socket) do
#     tokens = params["value"] || params["max_tokens"]
#     {tokens_int, _} = Integer.parse(tokens)
#     {:noreply, assign(socket, max_tokens: tokens_int)}
#   end

#   def handle_event("update_system_prompt", params, socket) do
#     prompt = params["value"] || params["system_prompt"]
#     {:noreply, assign(socket, system_prompt: prompt)}
#   end

#   def handle_event("update_schema", params, socket) do
#     schema = params["value"] || params["schema"]
#     {:noreply, assign(socket, schema_input: schema)}
#   end

#   def handle_event("set_output_type", %{"type" => type}, socket) do
#     {:noreply, assign(socket, output_type: String.to_atom(type))}
#   end

#   def handle_event("generate_structured", _params, socket) do
#     if socket.assigns.schema_input == "" do
#       {:noreply, socket}
#     else
#       live_view_pid = self()
#       model_spec = socket.assigns.model_spec
#       schema_input = socket.assigns.schema_input
#       output_type = socket.assigns.output_type
#       system_prompt = socket.assigns.system_prompt

#       spawn(fn ->
#         generate_structured_data(live_view_pid, model_spec, schema_input, output_type, system_prompt)
#       end)

#       {:noreply, assign(socket, loading: true, structured_result: nil)}
#     end
#   end

#   def handle_event("input_change", %{"message" => message}, socket) do
#     {:noreply, assign(socket, input: message)}
#   end

#   def handle_event("send_message", %{"message" => message}, socket) when message != "" do
#     user_message = %{
#       id: :crypto.strong_rand_bytes(8) |> Base.encode64(),
#       role: "user",
#       content: message
#     }

#     # Create assistant message placeholder
#     assistant_id = :crypto.strong_rand_bytes(8) |> Base.encode64()

#     assistant_message = %{
#       id: assistant_id,
#       role: "assistant",
#       content: ""
#     }

#     start_time = System.system_time(:millisecond)

#     updated_socket =
#       socket
#       |> assign(loading: true, input: "")
#       |> assign(messages: socket.assigns.messages ++ [user_message, assistant_message])
#       |> assign(current_assistant_id: assistant_id)

#     # Start async task for AI response streaming
#     live_view_pid = self()
#     model_spec = socket.assigns.model_spec

#     opts = [
#       temperature: socket.assigns.temperature,
#       max_tokens: socket.assigns.max_tokens,
#       system_prompt: socket.assigns.system_prompt
#     ]

#     # Build message history for the API call (exclude the placeholder assistant message)
#     message_history = updated_socket.assigns.messages |> Enum.slice(0..-2//1)

#     spawn(fn ->
#       stream_ai_response(live_view_pid, message_history, assistant_id, model_spec, opts, start_time)
#     end)

#     {:noreply, updated_socket}
#   end

#   def handle_event("send_message", _params, socket) do
#     {:noreply, socket}
#   end

#   def handle_event("change_provider", %{"value" => provider_str}, socket) do
#     IO.puts("ğŸ”§ ğŸš¨ PROVIDER CHANGE EVENT RECEIVED: #{provider_str}")
#     IO.puts("ğŸ”§ Current provider was: #{socket.assigns.selected_provider}")

#     provider = String.to_existing_atom(provider_str)
#     available_models = get_models_for_provider(provider) |> sort_models_alphabetically()

#     IO.puts("ğŸ”§ Found #{length(available_models)} models for #{provider}")

#     # Select first available model or keep current if it exists
#     selected_model =
#       case available_models do
#         [{model_id, _} | _] -> model_id
#         [] -> socket.assigns.selected_model
#       end

#     # Update model spec to use new provider:model
#     new_model_spec = "#{provider}:#{selected_model}"

#     IO.puts("ğŸ”§ New model spec: #{new_model_spec}")
#     IO.puts("ğŸ”§ Selected model: #{selected_model}")
#     IO.puts("ğŸ”§ Available models: #{length(available_models)}")

#     # Refresh API key status for new provider
#     api_key_status = [provider | socket.assigns.providers] |> Enum.uniq() |> check_api_keys()

#     socket =
#       assign(socket,
#         selected_provider: provider,
#         available_models: available_models,
#         selected_model: selected_model,
#         model_spec: new_model_spec,
#         api_key_status: api_key_status
#       )

#     IO.puts("ğŸ”§ âœ… Provider change completed - new state:")
#     IO.puts("ğŸ”§   Provider: #{socket.assigns.selected_provider}")
#     IO.puts("ğŸ”§   Model: #{socket.assigns.selected_model}")
#     IO.puts("ğŸ”§   Models available: #{length(socket.assigns.available_models)}")

#     {:noreply, socket}
#   end

#   def handle_event("change_model", %{"value" => model_id}, socket) do
#     IO.puts("ğŸ”§ Changing model to: #{model_id}")

#     provider = socket.assigns.selected_provider
#     new_model_spec = "#{provider}:#{model_id}"

#     IO.puts("ğŸ”§ New model spec: #{new_model_spec}")

#     {:noreply,
#      assign(socket,
#        selected_model: model_id,
#        model_spec: new_model_spec
#      )}
#   end

#   def handle_event(event, params, socket) do
#     IO.puts("ğŸ”§ ğŸš¨ UNKNOWN EVENT: #{event} with params: #{inspect(params)}")
#     {:noreply, socket}
#   end

#   def handle_info({:stream_chunk, assistant_id, chunk}, socket) do
#     updated_messages =
#       Enum.map(socket.assigns.messages, fn msg ->
#         if msg.id == assistant_id do
#           %{msg | content: msg.content <> chunk}
#         else
#           msg
#         end
#       end)

#     {:noreply, assign(socket, messages: updated_messages)}
#   end

#   def handle_info({:stream_complete, _assistant_id, _start_time}, socket) do
#     {:noreply, assign(socket, loading: false)}
#   end

#   def handle_info({:stream_complete, _assistant_id, _start_time, input_tokens, output_tokens, cost}, socket) do
#     # Accumulate metrics
#     new_total_input = socket.assigns.total_input_tokens + input_tokens
#     new_total_output = socket.assigns.total_output_tokens + output_tokens
#     new_total_cost = socket.assigns.total_cost + if cost, do: cost.total_cost, else: 0.0
#     new_api_calls = socket.assigns.api_calls + 1

#     IO.puts("ğŸ”§ ğŸ“Š Metrics updated:")
#     IO.puts("ğŸ”§   Input tokens: #{input_tokens} (total: #{new_total_input})")
#     IO.puts("ğŸ”§   Output tokens: #{output_tokens} (total: #{new_total_output})")

#     if cost,
#       do: IO.puts("ğŸ”§   Cost: #{CostCalculator.format_cost(cost)} (total: $#{:io_lib.format("~.6f", [new_total_cost])})")

#     IO.puts("ğŸ”§   API calls: #{new_api_calls}")

#     {:noreply,
#      assign(socket,
#        loading: false,
#        total_input_tokens: new_total_input,
#        total_output_tokens: new_total_output,
#        total_cost: new_total_cost,
#        api_calls: new_api_calls,
#        current_request_cost: cost
#      )}
#   end

#   def handle_info({:stream_error, assistant_id, error}, socket) do
#     updated_messages =
#       Enum.map(socket.assigns.messages, fn msg ->
#         if msg.id == assistant_id do
#           %{msg | content: "Error: " <> inspect(error)}
#         else
#           msg
#         end
#       end)

#     {:noreply, assign(socket, messages: updated_messages, loading: false)}
#   end

#   def handle_info({:structured_result, result}, socket) do
#     {:noreply, assign(socket, structured_result: result, loading: false)}
#   end

#   def handle_info({:structured_error, error}, socket) do
#     {:noreply, assign(socket, structured_result: %{error: inspect(error)}, loading: false)}
#   end

#   defp stream_ai_response(pid, message_history, assistant_id, model_spec, opts, start_time) do
#     IO.puts("ğŸ”§ Starting stream for model: #{model_spec}")
#     IO.puts("ğŸ”§ Message history: #{length(message_history)} messages")
#     IO.puts("ğŸ”§ Options: #{inspect(opts)}")

#     # Check if we have an API key for the provider
#     provider = model_spec |> String.split(":") |> List.first() |> String.to_atom()

#     case Jido.AI.config([provider, :api_key]) do
#       nil ->
#         IO.puts("ğŸ”§ No API key found, using test mode")
#         simulate_streaming_response(pid, message_history, assistant_id, model_spec, start_time)

#       _key ->
#         IO.puts("ğŸ”§ API key found, using real API")
#         real_streaming_response(pid, message_history, assistant_id, model_spec, opts, start_time)
#     end
#   end

#   defp simulate_streaming_response(pid, message_history, assistant_id, model_spec, start_time) do
#     IO.puts("ğŸ”§ Simulating streaming response...")

#     latest_message = List.last(message_history)
#     current_message = if latest_message, do: latest_message.content, else: "No message"

#     test_response =
#       "ğŸ¤– [TEST MODE] Hello! I'm simulating a response from #{model_spec}.\n\nYour latest message was: #{current_message}\n\nChat history: #{length(message_history)} messages\n\nThis is a test of the streaming functionality. In real mode, this would be a response from the actual AI model."

#     # Calculate simulated metrics
#     request_body = %{
#       "model" => model_spec,
#       "messages" => Enum.map(message_history, fn msg -> %{"role" => msg.role, "content" => msg.content} end)
#     }

#     input_tokens = TokenCounter.count_request_tokens(request_body)
#     output_tokens = TokenCounter.count_tokens(test_response)

#     # Simulate cost calculation (use a default rate for test mode)
#     test_cost = %{
#       input_tokens: input_tokens,
#       output_tokens: output_tokens,
#       # $0.01/1K tokens
#       input_cost: input_tokens * 0.00001,
#       # $0.02/1K tokens
#       output_cost: output_tokens * 0.00002,
#       total_cost: input_tokens * 0.00001 + output_tokens * 0.00002,
#       currency: "USD"
#     }

#     # Simulate streaming by sending chunks
#     chunks = test_response |> String.graphemes() |> Enum.chunk_every(3) |> Enum.map(&Enum.join/1)

#     Enum.each(chunks, fn chunk ->
#       # Simulate network delay
#       Process.sleep(50)
#       send(pid, {:stream_chunk, assistant_id, chunk})
#     end)

#     send(pid, {:stream_complete, assistant_id, start_time, input_tokens, output_tokens, test_cost})
#   end

#   defp real_streaming_response(pid, message_history, assistant_id, model_spec, opts, start_time) do
#     # Convert message history to format expected by stream_text
#     messages =
#       Enum.map(message_history, fn msg ->
#         %Message{role: String.to_atom(msg.role), content: msg.content}
#       end)

#     prompt =
#       if length(messages) == 1 do
#         # Single message - pass as string
#         List.first(messages).content
#       else
#         # Multiple messages - pass as message list
#         messages
#       end

#     # Calculate input tokens for this request
#     request_body = %{
#       "model" => model_spec,
#       "messages" => Enum.map(message_history, fn msg -> %{"role" => msg.role, "content" => msg.content} end)
#     }

#     input_tokens = TokenCounter.count_request_tokens(request_body)

#     IO.puts("ğŸ”§ ğŸ“¡ STREAM_TEXT CALL:")
#     IO.puts("ğŸ”§   Model: #{model_spec}")
#     IO.puts("ğŸ”§   Messages: #{length(messages)}")
#     IO.puts("ğŸ”§   Input Tokens: #{input_tokens}")
#     IO.puts("ğŸ”§   Temperature: #{opts[:temperature]}")
#     IO.puts("ğŸ”§   Max Tokens: #{opts[:max_tokens]}")
#     IO.puts("ğŸ”§   System Prompt: #{String.slice(opts[:system_prompt] || "none", 0, 50)}...")

#     case Jido.AI.stream_text(model_spec, prompt, opts) do
#       {:ok, stream} ->
#         IO.puts("ğŸ”§ Stream started successfully")

#         try do
#           output_tokens =
#             Enum.reduce(stream, 0, fn chunk, acc_tokens ->
#               if chunk == "" do
#                 acc_tokens
#               else
#                 chunk_tokens = TokenCounter.count_stream_tokens(chunk)
#                 IO.puts("ğŸ”§ Chunk: #{inspect(chunk)} (#{chunk_tokens} tokens)")
#                 send(pid, {:stream_chunk, assistant_id, chunk})
#                 acc_tokens + chunk_tokens
#               end
#             end)

#           # Calculate cost for this request
#           cost = calculate_request_cost(model_spec, input_tokens, output_tokens)

#           IO.puts("ğŸ”§ Stream completed")
#           IO.puts("ğŸ”§ Total output tokens: #{output_tokens}")
#           if cost, do: IO.puts("ğŸ”§ Request cost: #{CostCalculator.format_cost(cost)}")

#           send(pid, {:stream_complete, assistant_id, start_time, input_tokens, output_tokens, cost})
#         rescue
#           error ->
#             IO.puts("ğŸ”§ Stream error during enumeration: #{inspect(error)}")
#             send(pid, {:stream_error, assistant_id, error})
#         end

#       {:error, error} ->
#         IO.puts("ğŸ”§ Stream failed to start: #{inspect(error)}")
#         send(pid, {:stream_error, assistant_id, error})
#     end
#   end

#   defp calculate_request_cost(model_spec, input_tokens, output_tokens) do
#     case Jido.AI.model(model_spec) do
#       {:ok, model} ->
#         CostCalculator.calculate_cost(model, input_tokens, output_tokens)

#       {:error, _} ->
#         nil
#     end
#   end

#   defp generate_structured_data(pid, model_spec, schema_input, output_type, system_prompt) do
#     # Parse schema from string format
#     {schema, []} = Code.eval_string("[" <> schema_input <> "]")

#     prompt = "Generate structured data according to the schema provided."

#     opts = [
#       output_type: output_type,
#       system_prompt: system_prompt
#     ]

#     case Jido.AI.generate_object(model_spec, prompt, schema, opts) do
#       {:ok, result} ->
#         send(pid, {:structured_result, result})

#       {:error, error} ->
#         send(pid, {:structured_error, error})
#     end
#   rescue
#     error ->
#       send(pid, {:structured_error, "Schema parsing error: " <> inspect(error)})
#   end

#   defp format_markdown(content) do
#     case Earmark.as_html(content) do
#       {:ok, html, []} -> html
#       {:ok, html, _warnings} -> html
#       {:error, _html, _errors} -> content
#     end
#   end

#   defp get_models_for_provider(provider) do
#     case Jido.AI.Provider.Registry.fetch(provider) do
#       {:ok, provider_module} ->
#         provider_info = provider_module.provider_info()
#         provider_info.models |> Enum.to_list()

#       {:error, _} ->
#         []
#     end
#   end

#   defp sort_alphabetically(list) do
#     Enum.sort_by(list, fn
#       atom when is_atom(atom) -> Atom.to_string(atom)
#       str when is_binary(str) -> String.downcase(str)
#     end)
#   end

#   defp sort_models_alphabetically(models) do
#     Enum.sort_by(models, fn
#       {model_id, _model} -> String.downcase(model_id)
#       model_id when is_binary(model_id) -> String.downcase(model_id)
#     end)
#   end

#   defp check_api_keys(providers) do
#     Enum.map(providers, fn provider ->
#       case Jido.AI.config([provider, :api_key]) do
#         nil ->
#           IO.puts("ğŸ”§ No API key found for #{provider}")
#           {provider, :missing}

#         key when is_binary(key) ->
#           IO.puts("ğŸ”§ API key found for #{provider}: #{String.slice(key, 0, 10)}...")
#           {provider, :available}

#         other ->
#           IO.puts("ğŸ”§ Unexpected API key type for #{provider}: #{inspect(other)}")
#           {provider, :error}
#       end
#     end)
#   end
# end
